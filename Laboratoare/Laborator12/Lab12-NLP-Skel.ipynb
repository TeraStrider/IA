{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelucrarea Limbajului Natural: Analiza Sentimentelor\n",
    " - Tudor Berariu\n",
    " - Andrei Olaru\n",
    "\n",
    "Scopul acestui laborator îl reprezintă rezolvarea unei probleme ce implică analiza unor documente în limbaj natural și învățarea unui algoritm simplu de clasificare: **Naive Bayes**.\n",
    "\n",
    "## Analiza Sentimentelor\n",
    "\n",
    "O serie de probleme de inteligență artificială presupun asocierea unei clase unui document în limbaj natural. Exemple de astfel de probleme sunt: **clasificarea** email-urilor în *spam* sau *ham* sau a recenziilor unor filme în *pozitive* sau *negative*. În laboratorul de astăzi vom aborda problema din urmă.\n",
    "\n",
    "Folosind setul de date de aici: http://www.cs.cornell.edu/people/pabo/movie-review-data/ (2000 de recenzii de film), vom construi un model care să discrimineze între recenziile pozitive și recenziile negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmul Naive Bayes\n",
    "\n",
    "### Clasificare\n",
    "\n",
    "Având un set de date $\\langle \\mathbf{X}, \\mathbf{T} \\rangle$ compus din $N$ exemple $\\mathbf{x}^{(i)}$, $1 \\le i \\le N$, descrise prin $k$ atribute $(x^{(i)}_1, x^{(i)}_2, \\ldots, x^{(i)}_k)$ și etichetate cu o clasă $t^{(i)} \\in \\mathcal{C}$, se cere construirea unui clasificator care să eticheteze exemple noi.\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "**Naive Bayes** reprezintă o *metodă statistică inductivă* de clasificare, bazată pe Teorema lui Bayes pentru exprimarea relației dintre probabilitatea *a priori* și probabilitatea *posterioară* ale unei ipoteze.\n",
    "\n",
    "$$P(c \\vert \\mathbf{x}) = \\frac{P(\\mathbf{x} \\vert c) \\cdot P(c)}{P(\\mathbf{x})}$$\n",
    "\n",
    " - $P(c)$ reprezintă probabilitatea *a priori* a clasei $c$\n",
    " - $P(c \\vert \\mathbf{x})$ reprezintă probabilitatea *a posteriori* (după observarea lui $\\mathbf{x}$)\n",
    " - $P(\\mathbf{x} \\vert c)$ reprezitnă probabilitatea ca $\\mathbf{x}$ să aparțină clasei $c$ (*verosimilitatea*)\n",
    " \n",
    "Un clasificator **Naive Bayes** funcționează pe principiul verosimilității maxime (eng. *maximum likelihood*), deci alege clasa $c$ pentru care probabilitatea $P(c \\vert x)$ este maximă:\n",
    "\n",
    "$$c_{MAP} = \\underset{c \\in \\mathcal{C}}{\\arg\\max} P(c \\vert \\mathbf{x}) = \\underset{c \\in \\mathcal{C}}{\\arg\\max} \\frac{P(\\mathbf{x} \\vert c) \\cdot P(c)}{P(x)} = \\underset{c \\in \\mathcal{C}}{\\arg\\max} P(\\mathbf{x} \\vert c) \\cdot P(c)$$\n",
    "\n",
    "Cum fiecare exemplu $\\mathbf{x}$ este descris prin $K$ atribute:\n",
    "\n",
    "$$c_{MAP} = \\underset{c \\in \\mathcal{C}}{\\arg\\max} P(x_1, x_2, \\ldots x_K \\vert c) \\cdot P(c)$$\n",
    "\n",
    "Algoritmul **Naive Bayes** face o presupunere simplificatoare, și anume, că atributele unui exemplu sunt *condițional independente* odată ce clasa este cunoscută:\n",
    "\n",
    "$$P(\\mathbf{x} \\vert c) = \\displaystyle\\prod_i P(x_i \\vert c)$$\n",
    "\n",
    "Astfel clasa pe care o prezice un clasificator **Naive Bayes** este:\n",
    "\n",
    "$$c_{NB} = \\underset{c \\in \\mathcal{C}}{\\arg\\max} P(c) \\cdot \\displaystyle \\prod_{i}^{K} P(x_i \\vert c)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificarea documentelor\n",
    "\n",
    "Pentru clasificare documentele vor fi reprezentate prin vectori binari de lungimea vocabularului (eng. *bag of words*). Practic fiecare document va avea 1 pe pozițiile corspunzătoare cuvintelor pe care le conține și 0 pe toate celelalte poziții. Dimensiunea unui exemplu $\\mathbf{x}$ este, deci, numărul de cuvinte diferite din setul de date.\n",
    "\n",
    "### Estimarea parametrilor modelului Naive Bayes\n",
    "\n",
    "Probabilitatea _a priori_ pentru o clasă $c \\in \\mathcal{C}$:\n",
    "\n",
    "$$P(c) = \\frac{\\#\\text{ docs in class }c}{\\#\\text{ total docs}}$$\n",
    "\n",
    "$P(x_i \\vert c)$ va reprezenta probabilitatea de a apărea cuvântul $x_i$ într-un document din clasa $c$ și o vom estima cu raportul dintre numărul de apariții ale cuvântului $x_i$ în documentele din clasa $c$ și numărul total de cuvinte ale acelor documente:\n",
    "\n",
    "$$P(x_i \\vert c) = \\frac{\\#\\text{ aparitii ale lui } x_i \\text{ in documente din clasa } c}{\\#\\text{ numar total de cuvinte in documentele din clasa } c}$$\n",
    "\n",
    "Deoarece este posibil ca un cuvant _rar_ ce apare într-un exemplu de test să nu se găsească deloc într-una din clase, se poate întâmpla ca un astfel de _accident_ să anuleze complet o probabilitate. Dacă un singur factor al unui produs este zero, atunci produsul devine zero. De aceea vom folosi netezire Laplace (eng. _Laplace smoothing_):\n",
    "\n",
    "$$P(x_i \\vert c) = \\frac{\\#\\text{ aparitii ale lui } x_i \\text{ in documente din clasa } c + \\alpha}{\\#\\text{ numar total de cuvinte in documentele din clasa } c + \\vert \\mathit{Voc} \\vert \\cdot \\alpha}$$\n",
    "\n",
    "unde $\\mathit{Voc}$ este dimensiunea vocabularului."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setul de date\n",
    "\n",
    " 1. Descărcați setul de date **polarity dataset v2.0** de aici http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    " 2. Dezarhivați fișierul **review_polarity.tar.gz** și rearhivați directorul review_polarity ca zip.\n",
    " 3. Plasați / încărcați **review_polarity.zip** în directorul de lucru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recenzii pozitive: 1000; Recenzii negative: 1000\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zipFile = zipfile.ZipFile(\"review_polarity.zip\")\n",
    "\n",
    "pos_files = [f for f in zipFile.namelist() if '/pos/cv' in f]\n",
    "neg_files = [f for f in zipFile.namelist() if '/neg/cv' in f]\n",
    "\n",
    "pos_files.sort()\n",
    "neg_files.sort()\n",
    "\n",
    "print(\"Recenzii pozitive: \" + str(len(pos_files)) + \"; Recenzii negative: \" + str(len(neg_files)))\n",
    "\n",
    "# Raspunsul asteptat: \"Recenzii pozitive: 1000; Recenzii negative: 1000\"\n",
    "assert(len(pos_files) == 1000 and len(neg_files) == 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setul de antrenare și setul de testare\n",
    "\n",
    "Vom folosi 80% din datele din fiecare clasă pentru antrenare și 20% pentru testare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pos_no = int(.8 * len(pos_files))\n",
    "tr_neg_no = int(.8 * len(neg_files))\n",
    "\n",
    "from random import shuffle\n",
    "shuffle(pos_files)\n",
    "shuffle(neg_files)\n",
    "\n",
    "pos_train = pos_files[:tr_pos_no] # Recenzii pozitive pentru antrenare\n",
    "pos_test  = pos_files[tr_pos_no:] # Recenzii pozitive pentru testare\n",
    "neg_train = neg_files[:tr_neg_no] # Recenzii negative pentru antrenare\n",
    "neg_test  = neg_files[tr_neg_no:] # Recenzii negative pentru testare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construirea vocabularului și calculul parametrilor\n",
    "\n",
    "Funcția `parse_document` primește calea către unul dinte fișierele aflate în arhivă și întoarce cuvintele din acest fișier (exceptând cuvintele cu o singură literă și pe cele din lista `STOP_WORDS`. Implementați funcția `count_words` astfel încât să întoarcă un dicționar cu o intrare pentru fiecare cuvânt care să conțină un tuplu cu două valori: numărul de apariții ale acelui cuvânt în rencezii pozitive și numărul de apariții în recenzii negative. În afara acelui dicționar se vor întoarce și numărul total de cuvinte din recenziile pozitive și numărul total de cuvinte din recenziile negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocabularul are  45155  cuvinte.\n523894  cuvinte in recenziile pozitive si  469169  cuvinte in recenziile negative\nCuvantul 'beautiful' are  [149, 81]  aparitii.\nCuvantul 'awful' are  [15, 94]  aparitii.\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS = []\n",
    "#STOP_WORDS = [line.strip() for line in open(\"Lab12-stop_words\")]\n",
    "\n",
    "import re\n",
    "\n",
    "POS = 0\n",
    "NEG = 1\n",
    "\n",
    "def parse_document(path):\n",
    "    for word in re.findall(r\"[-\\w']+\", zipFile.read(path).decode(\"utf-8\")):\n",
    "        if len(word) > 1 and word not in STOP_WORDS:\n",
    "            yield word\n",
    "\n",
    "def count_words():\n",
    "    vocabulary = {}\n",
    "    pos_words_no = 0\n",
    "    neg_words_no = 0\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # <TODO 1> numrati aparitiile in documente pozitive si\n",
    "    # in documente negative ale fiecarui cuvant, precum si numarul total\n",
    "    # de cuvinte din fiecare tip de recenzie\n",
    "    for pos_file in pos_train:\n",
    "        for word in parse_document(pos_file):\n",
    "            pos_words_no += 1\n",
    "            if word in vocabulary:\n",
    "                vocabulary[word][POS] += 1\n",
    "            else:\n",
    "                vocabulary[word] = [1, 0]\n",
    "\n",
    "    for neg_file in neg_train:\n",
    "        for word in parse_document(neg_file):\n",
    "            neg_words_no += 1\n",
    "            if word in vocabulary:\n",
    "                vocabulary[word][NEG] += 1\n",
    "            else:\n",
    "                vocabulary[word] = [0, 1]\n",
    "    # ------------------------------------------------------\n",
    "\n",
    "    return (vocabulary, pos_words_no, neg_words_no)\n",
    "\n",
    "# -- VERIFICARE --\n",
    "training_result_words = count_words()\n",
    "\n",
    "(voc, p_no, n_no) = training_result_words\n",
    "print(\"Vocabularul are \", len(voc), \" cuvinte.\")\n",
    "print(p_no, \" cuvinte in recenziile pozitive si \", n_no, \" cuvinte in recenziile negative\")\n",
    "print(\"Cuvantul 'beautiful' are \", voc.get(\"beautiful\", (0, 0)), \" aparitii.\")\n",
    "print(\"Cuvantul 'awful' are \", voc.get(\"awful\", (0, 0)), \" aparitii.\")\n",
    "\n",
    "# Daca se comentează liniile care reordonează aleator listele cu exemplele pozitive și negative,\n",
    "# rezultatul așteptat este:\n",
    "#\n",
    "# Vocabularul are  44895  cuvinte.\n",
    "# 526267  cuvinte in recenziile pozitive si  469812  cuvinte in recenziile negative\n",
    "# Cuvantul 'beautiful' are  (165, 75)  aparitii.\n",
    "# Cuvantul 'awful' are  (16, 89)  aparitii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicția sentimentului unei recenzii noi\n",
    "\n",
    "Implementați funcția `predict` care primește parametrii `params` (vocabularul, numărul total de cuvinte din recenziile pozitive și numărul total de cuvinte din recenziile negative) și `path` (calea către o recenzie din cadrul arhivei) și întoarce clasa mai probabilă și logaritmul acelei probabilități. Al treilea argument (opțional) al funcției `predict` este coeficientul pentru netezire Laplace.\n",
    "\n",
    "Așa cum a fost explicat anterior, clasa pe care o prezice un clasificator **Naive Bayes** este dată de următoarea expresie:\n",
    "\n",
    "$$c_{NB} = \\underset{c \\in \\mathcal{C}}{\\arg\\max} P(c) \\cdot \\displaystyle \\prod_{i}^{K} P(x_i \\vert c)$$\n",
    "\n",
    "Pentru a evita lucrul cu numere foarte mici ce pot rezulta din produsul multor valori subunitare, vom logaritma expresiile date:\n",
    "\n",
    "$$c_{NB} = \\underset{c \\in \\mathcal{C}}{\\arg\\max} \\log(P(c)) + \\displaystyle\\sum_{i}^{K} \\log(P(x_i \\vert c))$$\n",
    "\n",
    "Pentru calculul probabilitatilor, vedeti sectiunea \"Estimarea parametrilor modelului Naive Bayes\", mai sus. În cod, `log_pos` și `log_neg` trebuie însumate cu logaritmul pentru fiecare exemplu -- $ \\log(P(c)) $ este deja adunat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "maybe the most important thing about this movie is that it's not handled like the hallmark hall of fame movie of the month , because it very well could have been a manipulative tearjerker , broadcasted on abc on a monday night , starring kelly martin and yasmeen bleeth , respectively . \nbecause it's not handled like the greatest story ever told is precisely why it's so great . \nunderneath the to-die-for cinematography , the brilliant acting , and incessantly wonderful direction is a film of modesty , not sure whether or not this story is totally great but with the balls to run with it , tell it in a certain original way . \nit doesn't merely go from plot point to plot point . \nit goes from character to character . \nit obsesses itself with the depth and the style of it all , and makes the story of a world-reknowned cellist who contracts ms and dies prematurely into the story of two sisters , both musicians , who have a totally unique relationship . \nit's that their relationship is the center of the story that makes this film transcend any cornball , shamelessly tired tearjerker qualities it could have had and makes this , unlike \" patch adams , \" effortlessly emotional and real . \nin short , this movie is just awesome . \nit merely tells its story really well , and that's something that just has to be commended these days , when most stories are botched because they're not told by great storytellers . \ndirector anand tucker tells this story well . \nhe overdramaticizes everything , but still keeps it real . \nthe film tells the story of hilary and jacqueline du pr ? ( rachel griffiths and emily watson , respectively ) , two sisters who are first seen in childhood ( played by auriol evans and keely flanders , respectively ) as the very best of friends . \nthey are also both musicians , hilary a flutist and jackie a cellist , and when it all begins , both are considered child prodigies , but hilary is seen as the better of the two . \njackie , a bit jealous , works and works at her playing skills , and soon the tables are turned . \nwhen they both hit adulthood , hilary strives for a comeback , while her sister is playing in famous halls around the world , but instead of fame , captures the heart of a hapless , joyful conductor , kiffer finzi ( david morissey , in a semi-star-making turn ) . \nthey marry , after a short courtship , and move to a lovely country house , making jackie incredibly jealous since her cello playing becomes a symbol of her current life : when she plays , she has the eyes of the world , but when she stops , she's alone . \nshe enters into a shallow relationship with an equally famous pianist , daniel barenboim ( james frain ) , in hopes that she may overcloud her sister , but she eventually begins to lose it , and runs away to hilary's country home , where she hopes to gain admittance by hilary to sleep with her husband , since no one she sleeps with gives her any pleasure . \nit's all terribly melodramtic , as you can see , and by the time jackie has contracted ms ( in a brilliantly edited scene that surpasses the breakdown scene in the semi-smiliar \" shine \" in technical and emotional devastation ) , it would have been the time that i could easily call the sign for melodramatic overload if it hadn't been handled in such a way . \nthe key thing here is that it's not about her gradual death and slip into insanity but rather that it's about her tumultuous relationship with her sister , which , i might add , is perfectly realized . \ntheir relationship is the most down-to-earth complex entity of the year : they love eachother more than anyone else in the entire world , but they're also completely jealous of one another . \nwhen a young jackie surpasses her playing abilities , she tries in vain to make a comeback but can't , and almost seems to marry to get back at jackie for her success . \nwhen jackie lands on top and sees her sister marry a wonderful man , she is jealous of her lifestyle to the most extensive brinks that i've ever seen in a film ( only two sisters who truly love eachother would dare share the same man ) . \nand the whole time , their love for eachother is never doubted or even tested . \nanother thing i really liked is emily watson's performance . \ni usually make it a note to never overpraise an actor for playing either a drunkard or a lunatic or someone with a mortal disease ( or any combination of the three ) . \nmy reasoning for this is that it's a fucking easy job . \nthe worst case for this very year may be thandie newton in \" beloved \" : sure , she's good , but what's so tough about playing a woman who stumbles around , slurs her words together , and acts like a three year old inside a 20-year old's body ? \nhell , i could play that if i had a pair of breasts . \nin that same exact movie , though , is a performance by kimberly elise where she has to be the rock that holds the family together as her mother slowly goes insane , her brothers run off never to be seen again , and her mother's lover is scared off . \nshe has to actually deal with real emotions , something much harder than mere stumbling about . \nbut the academy of arts and sciences loves loves loves overpraising performances like newtons . \nif you don't believe me , look at jack nicholson's performance in \" as good as it gets \" : great performance , but easy job . \nthis isn't so for watson , though , because her insanity comes from real emotions , not just a plot point . \nand thanks to the opening sequence , where we see her and hilary as kids , we understand the motives behind all her actions , and by the time she actually contracts ms and begins to loose her sanity and her life , we've already understood that this is the last straw for a woman plagued with terrible neuroses . \nrachel griffiths , who would have otherwise been the understudy to watson's protagonist , actually matches watson step-for-step , because as watson grows insane , and demands unspeakable things from her , griffiths holds her own , and has to deal with what she is able to give her sister who needs emotional help from her . \ngriffiths , an otherwise unknown actress ( and watson being famous from \" breaking the waves \" and \" the boxer \" ) , is absolutely brilliant , just as absolutely brilliant as watson is , and if the academy and all the other critics groups , who've already deemed watson's performance the best of the year , glance over hers because she's the one who doesn't get to go insane ( read : she gets the boring role ) , then the scream of hysteria you hear will be from me . \nafter all , griffiths has the thankless job of keeping things real - the tom cruise role in \" rainman \" ( the one who should have gotten oscar consideration and not hoffman ) . \nshe does , and if anyone deserves accolades from the academy this year , it's griffiths . \ntogether , the two actresses work extremely well , though , and both have to go through deep emotional hell , the likes of which haven't been seen this year . \nif it hadn't been for an otherwise not-totally-great final section that deals way too much with jackie and not enough with hilary ( when the two had gotten equal treatment for the entirety ) , i'd say this is one of the top ten best films of the year . \nit's so close to perfection , in its structure , its treatment of its subject , and its beautiful technical specifications ( cinematography nomination , without a shred of doubt in my mind , and maybe film editing ) , that it's nearly a shame that it's not the flawless gem that it should be . \nbut , hey , as it is , i can hardly complain . \n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('pos', -8810.422699291488)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "def predict(params, path, alpha = 1):\n",
    "    (vocabulary, pos_words_no, neg_words_no) = params\n",
    "    laplace = len(vocabulary.keys()) * alpha\n",
    "    log_pos = log(0.5)\n",
    "    log_neg = log(0.5)\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    # <TODO 2> Calculul logaritmilor probabilităților\n",
    "    for word in parse_document(path):\n",
    "        cnt = vocabulary.get(word, [0, 0])\n",
    "\n",
    "        log_pos += log((cnt[POS] + alpha) / (pos_words_no + laplace))\n",
    "        log_neg += log((cnt[NEG] + alpha) / (neg_words_no + laplace))\n",
    "    # ----------------------------------------------------------------------\n",
    "\n",
    "    if log_pos > log_neg:\n",
    "        return \"pos\", log_pos\n",
    "    else:\n",
    "        return \"neg\", log_neg\n",
    "\n",
    "# -- VERIFICARE --\n",
    "print(zipFile.read(pos_test[14]).decode(\"utf-8\"))\n",
    "predict(training_result_words, pos_test[14])\n",
    "\n",
    "# Daca se comentează liniile care reordonează aleator listele cu exemplele pozitive și negative,\n",
    "# rezultatul așteptat este:\n",
    "#\n",
    "# ('pos', -1790.27088356391) pentru un film cu Hugh Grant și Julia Roberts (o mizerie siropoasă)\n",
    "#\n",
    "# Recenzia este clasificată corect ca fiind pozitivă."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluarea modelului\n",
    "\n",
    "Pentru a evalua modelul vom calcula acuratețea acestuia și matricea de confuzie, folosind datele de test (`pos_test` și `neg_test`).\n",
    "\n",
    "[Vedeți aici despre matricea de confuzie](https://en.wikipedia.org/wiki/Confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acuratetea pe setul de date de test:  81.75 %. Matricea de confuzie:\n    |     pos      |     neg    \n--- + ------------ + ------------\npos |     160      |      40    \nneg |      33      |     167    \n"
     ]
    }
   ],
   "source": [
    "def evaluate(params, prediction_func):\n",
    "    conf_matrix = {}\n",
    "    conf_matrix[\"pos\"] = {\"pos\": 0, \"neg\": 0}\n",
    "    conf_matrix[\"neg\"] = {\"pos\": 0, \"neg\": 0}\n",
    "    accuracy = 0\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    # <TODO 3> : Calcularea acurateței și a matricei de confuzie\n",
    "    for test_file in pos_test:\n",
    "        if 'pos' == prediction_func(params, test_file)[POS]:\n",
    "            conf_matrix['pos']['pos'] += 1\n",
    "        else:\n",
    "            conf_matrix['pos']['neg'] += 1\n",
    "\n",
    "    for test_file in neg_test:\n",
    "        if 'neg' == prediction_func(params, test_file)[POS]:\n",
    "            conf_matrix['neg']['neg'] += 1\n",
    "        else:\n",
    "            conf_matrix['neg']['pos'] += 1\n",
    "\n",
    "    accuracy = (conf_matrix['pos']['pos'] + conf_matrix['neg']['neg']) \\\n",
    "        / (len(pos_test) + len(neg_test))\n",
    "    #------------------------------------------------------------\n",
    "    \n",
    "    return accuracy, conf_matrix\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def print_confusion_matrix(cm):\n",
    "    print(\"    | \", \"{0:^10}\".format(\"pos\"), \" | \", \"{0:^10}\".format(\"neg\"))\n",
    "    print(\"{0:-^3}\".format(\"\"), \"+\", \"{0:-^12}\".format(\"\"), \"+\", \"{0:-^12}\".format(\"-\", fill=\"-\"))\n",
    "    print(\"pos | \", \"{0:^10}\".format(cm[\"pos\"][\"pos\"]), \" | \", \"{0:^10}\".format(cm[\"pos\"][\"neg\"]))\n",
    "    print(\"neg | \", \"{0:^10}\".format(cm[\"neg\"][\"pos\"]), \" | \", \"{0:^10}\".format(cm[\"neg\"][\"neg\"]))\n",
    "\n",
    "\n",
    "# -- VERIFICARE --\n",
    "(acc_words, cm_words) = evaluate(training_result_words, predict)\n",
    "print(\"Acuratetea pe setul de date de test: \", acc_words * 100, \"%. Matricea de confuzie:\")\n",
    "print_confusion_matrix(cm_words)\n",
    "\n",
    "# Daca se comentează liniile care reordonează aleator listele cu exemplele pozitive și negative,\n",
    "# rezultatul așteptat este:\n",
    "#\n",
    "# Acuratetea pe setul de date de test:  80.5 %. Matricea de confuzie:\n",
    "#     |     pos      |     neg    \n",
    "# --- + ------------ + ------------\n",
    "# pos |     155      |      45    \n",
    "# neg |      33      |     167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Un model mai bun? Să folosim bigrame? Da!\n",
    "\n",
    "Implementați funcția `count_bigrams`, similară cu `count_words`, doar că de data aceasta dicționarul va conține bigramele din text. Funcția va întoarce tot trei elemente: dicționarul cu aparițiile în recenzii pozitive și în recenzii negative ale bigramelor, numărul total de bigrame din recenziile pozitive și numărul total de bigrame din recenziile negative.\n",
    "\n",
    "Salvați o bigramă prin concatenarea primului cuvânt, semnului \":\" și a celui de-al doilea cuvânt. De exemplu: `\"texas:ranger\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tabelul are  429728  bigrame.\n523094  bigrame in recenziile pozitive si  468369  bigrame in recenziile negative\nBigrama 'beautiful actress' are  [2, 0]  aparitii.\nBigrama 'awful movie' are  [1, 4]  aparitii.\n"
     ]
    }
   ],
   "source": [
    "def count_bigrams():\n",
    "    bigrams = {}\n",
    "    pos_bigrams_no = 0\n",
    "    neg_bigrams_no = 0\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # <TODO 4>: Numarati bigramele\n",
    "    for train_file in pos_train:\n",
    "        train_words = list(parse_document(train_file))\n",
    "\n",
    "        train_len = len(train_words) - 1\n",
    "        pos_bigrams_no += train_len\n",
    "\n",
    "        for i in range(train_len):\n",
    "            bi = f'{train_words[i]}:{train_words[i + 1]}'\n",
    "            if bi in bigrams:\n",
    "                bigrams[bi][POS] += 1\n",
    "            else:\n",
    "                bigrams[bi] = [1, 0]\n",
    "\n",
    "    for train_file in neg_train:\n",
    "        train_words = list(parse_document(train_file))\n",
    "\n",
    "        train_len = len(train_words) - 1\n",
    "        neg_bigrams_no += train_len\n",
    "\n",
    "        for i in range(train_len):\n",
    "            bi = f'{train_words[i]}:{train_words[i + 1]}'\n",
    "            if bi in bigrams:\n",
    "                bigrams[bi][NEG] += 1\n",
    "            else:\n",
    "                bigrams[bi] = [0, 1]\n",
    "    #-----------------------------------------------\n",
    "\n",
    "    return bigrams, pos_bigrams_no, neg_bigrams_no\n",
    "\n",
    "# -- VERIFICARE --\n",
    "training_result_bigrams = count_bigrams()\n",
    "\n",
    "(big, pos_b, neg_b) = training_result_bigrams\n",
    "print(\"Tabelul are \", len(big), \" bigrame.\")\n",
    "print(pos_b, \" bigrame in recenziile pozitive si \", neg_b, \" bigrame in recenziile negative\")\n",
    "print(\"Bigrama 'beautiful actress' are \", big.get(\"beautiful:actress\", (0, 0)), \" aparitii.\")\n",
    "print(\"Bigrama 'awful movie' are \", big.get(\"awful:movie\", (0, 0)), \" aparitii.\")\n",
    "\n",
    "# Daca se comentează liniile care reordonează aleator listele cu exemplele pozitive și negative,\n",
    "# rezultatul așteptat este:\n",
    "#\n",
    "# Tabelul are  428997  bigrame.\n",
    "# 525467  bigrame in recenziile pozitive si  469012  bigrame in recenziile negative\n",
    "# Bigrama 'beautiful actress' are  (2, 0)  aparitii.\n",
    "# Bigrama 'awful movie' are  (1, 4)  aparitii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcția de predicție folosind bigrame\n",
    "\n",
    "Implementați funcția `predict2` care să calculeze logaritmul probabilității fiecărei clase pe baza bigramelor din text. Trebuie să calculați `log_pos` și `log_neg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "maybe the most important thing about this movie is that it's not handled like the hallmark hall of fame movie of the month , because it very well could have been a manipulative tearjerker , broadcasted on abc on a monday night , starring kelly martin and yasmeen bleeth , respectively . \nbecause it's not handled like the greatest story ever told is precisely why it's so great . \nunderneath the to-die-for cinematography , the brilliant acting , and incessantly wonderful direction is a film of modesty , not sure whether or not this story is totally great but with the balls to run with it , tell it in a certain original way . \nit doesn't merely go from plot point to plot point . \nit goes from character to character . \nit obsesses itself with the depth and the style of it all , and makes the story of a world-reknowned cellist who contracts ms and dies prematurely into the story of two sisters , both musicians , who have a totally unique relationship . \nit's that their relationship is the center of the story that makes this film transcend any cornball , shamelessly tired tearjerker qualities it could have had and makes this , unlike \" patch adams , \" effortlessly emotional and real . \nin short , this movie is just awesome . \nit merely tells its story really well , and that's something that just has to be commended these days , when most stories are botched because they're not told by great storytellers . \ndirector anand tucker tells this story well . \nhe overdramaticizes everything , but still keeps it real . \nthe film tells the story of hilary and jacqueline du pr ? ( rachel griffiths and emily watson , respectively ) , two sisters who are first seen in childhood ( played by auriol evans and keely flanders , respectively ) as the very best of friends . \nthey are also both musicians , hilary a flutist and jackie a cellist , and when it all begins , both are considered child prodigies , but hilary is seen as the better of the two . \njackie , a bit jealous , works and works at her playing skills , and soon the tables are turned . \nwhen they both hit adulthood , hilary strives for a comeback , while her sister is playing in famous halls around the world , but instead of fame , captures the heart of a hapless , joyful conductor , kiffer finzi ( david morissey , in a semi-star-making turn ) . \nthey marry , after a short courtship , and move to a lovely country house , making jackie incredibly jealous since her cello playing becomes a symbol of her current life : when she plays , she has the eyes of the world , but when she stops , she's alone . \nshe enters into a shallow relationship with an equally famous pianist , daniel barenboim ( james frain ) , in hopes that she may overcloud her sister , but she eventually begins to lose it , and runs away to hilary's country home , where she hopes to gain admittance by hilary to sleep with her husband , since no one she sleeps with gives her any pleasure . \nit's all terribly melodramtic , as you can see , and by the time jackie has contracted ms ( in a brilliantly edited scene that surpasses the breakdown scene in the semi-smiliar \" shine \" in technical and emotional devastation ) , it would have been the time that i could easily call the sign for melodramatic overload if it hadn't been handled in such a way . \nthe key thing here is that it's not about her gradual death and slip into insanity but rather that it's about her tumultuous relationship with her sister , which , i might add , is perfectly realized . \ntheir relationship is the most down-to-earth complex entity of the year : they love eachother more than anyone else in the entire world , but they're also completely jealous of one another . \nwhen a young jackie surpasses her playing abilities , she tries in vain to make a comeback but can't , and almost seems to marry to get back at jackie for her success . \nwhen jackie lands on top and sees her sister marry a wonderful man , she is jealous of her lifestyle to the most extensive brinks that i've ever seen in a film ( only two sisters who truly love eachother would dare share the same man ) . \nand the whole time , their love for eachother is never doubted or even tested . \nanother thing i really liked is emily watson's performance . \ni usually make it a note to never overpraise an actor for playing either a drunkard or a lunatic or someone with a mortal disease ( or any combination of the three ) . \nmy reasoning for this is that it's a fucking easy job . \nthe worst case for this very year may be thandie newton in \" beloved \" : sure , she's good , but what's so tough about playing a woman who stumbles around , slurs her words together , and acts like a three year old inside a 20-year old's body ? \nhell , i could play that if i had a pair of breasts . \nin that same exact movie , though , is a performance by kimberly elise where she has to be the rock that holds the family together as her mother slowly goes insane , her brothers run off never to be seen again , and her mother's lover is scared off . \nshe has to actually deal with real emotions , something much harder than mere stumbling about . \nbut the academy of arts and sciences loves loves loves overpraising performances like newtons . \nif you don't believe me , look at jack nicholson's performance in \" as good as it gets \" : great performance , but easy job . \nthis isn't so for watson , though , because her insanity comes from real emotions , not just a plot point . \nand thanks to the opening sequence , where we see her and hilary as kids , we understand the motives behind all her actions , and by the time she actually contracts ms and begins to loose her sanity and her life , we've already understood that this is the last straw for a woman plagued with terrible neuroses . \nrachel griffiths , who would have otherwise been the understudy to watson's protagonist , actually matches watson step-for-step , because as watson grows insane , and demands unspeakable things from her , griffiths holds her own , and has to deal with what she is able to give her sister who needs emotional help from her . \ngriffiths , an otherwise unknown actress ( and watson being famous from \" breaking the waves \" and \" the boxer \" ) , is absolutely brilliant , just as absolutely brilliant as watson is , and if the academy and all the other critics groups , who've already deemed watson's performance the best of the year , glance over hers because she's the one who doesn't get to go insane ( read : she gets the boring role ) , then the scream of hysteria you hear will be from me . \nafter all , griffiths has the thankless job of keeping things real - the tom cruise role in \" rainman \" ( the one who should have gotten oscar consideration and not hoffman ) . \nshe does , and if anyone deserves accolades from the academy this year , it's griffiths . \ntogether , the two actresses work extremely well , though , and both have to go through deep emotional hell , the likes of which haven't been seen this year . \nif it hadn't been for an otherwise not-totally-great final section that deals way too much with jackie and not enough with hilary ( when the two had gotten equal treatment for the entirety ) , i'd say this is one of the top ten best films of the year . \nit's so close to perfection , in its structure , its treatment of its subject , and its beautiful technical specifications ( cinematography nomination , without a shred of doubt in my mind , and maybe film editing ) , that it's nearly a shame that it's not the flawless gem that it should be . \nbut , hey , as it is , i can hardly complain . \n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('pos', -14656.244035488971)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "def predict2(params, path, alpha = 1):\n",
    "    (bigrams, pos_bigrams_no, neg_bigrams_no) = params\n",
    "    log_pos = log(0.5)\n",
    "    log_neg = log(0.5)\n",
    "    laplace = len(bigrams.keys()) * alpha\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    # <TODO 5> Calculul logaritmilor probabilităților folosind bigramele\n",
    "    train_words = list(parse_document(path))\n",
    "    train_len = len(train_words) - 1\n",
    "\n",
    "    for i in range(train_len):\n",
    "        bi = f'{train_words[i]}:{train_words[i + 1]}'\n",
    "        cnt = bigrams.get(bi, [0, 0])\n",
    "    \n",
    "        log_pos += log((cnt[POS] + alpha) / (pos_bigrams_no + laplace))\n",
    "        log_neg += log((cnt[NEG] + alpha) / (neg_bigrams_no + laplace))\n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    if log_pos > log_neg:\n",
    "        return \"pos\", log_pos\n",
    "    else:\n",
    "        return \"neg\", log_neg\n",
    "    \n",
    "# -- VERIFICARE --\n",
    "print(zipFile.read(pos_test[14]).decode(\"utf-8\"))\n",
    "predict2(training_result_bigrams, pos_test[14])\n",
    "\n",
    "# Daca se comentează liniile care reordonează aleator listele cu exemplele pozitive și negative,\n",
    "# rezultatul așteptat este:\n",
    "#\n",
    "# ('pos', -3034.428732037113) pentru același film cu Hugh Grant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acuratetea pe setul de date de test, cu bigrame:  82.25 %. Matricea de confuzie:\n    |     pos      |     neg    \n--- + ------------ + ------------\npos |     156      |      44    \nneg |      27      |     173    \n"
     ]
    }
   ],
   "source": [
    "# -- VERIFICARE --\n",
    "(acc_bigrams, cm_bigrams) = evaluate(training_result_bigrams, predict2)\n",
    "print(\"Acuratetea pe setul de date de test, cu bigrame: \", acc_bigrams * 100, \"%. Matricea de confuzie:\")\n",
    "print_confusion_matrix(cm_bigrams)\n",
    "\n",
    "# Daca se comentează liniile care reordonează aleator listele cu exemplele pozitive și negative,\n",
    "# rezultatul așteptat este:\n",
    "#\n",
    "# Acuratetea pe setul de date de test:  84.5 %. Matricea de confuzie:\n",
    "#     |     pos      |     neg    \n",
    "# --- + ------------ + ------------\n",
    "# pos |     161      |      39    \n",
    "# neg |      23      |     177   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La final...\n",
    "\n",
    " 1. Decomentați liniile care reordonează aleator listele cu exemplele pozitive și cele negative (secțiunea \"Setul de antrenare și setul de testare\"). Rulați de mai multe ori. Este întotdeauna mai bun modelul cu bigrame? Acuratețea variază mult de la o rulare la alta?\n",
    " 2. Încercați să eliminați cuvintele de legătură (linia cu `STOP_WORDS`, din secțiunea \"Construirea vocabularului...\"). Ce impact are asupra performanței celor două modele?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acuratetea pe setul de date de test, cu cuvinte simple:  81.75 %. Matricea de confuzie:\n    |     pos      |     neg    \n--- + ------------ + ------------\npos |     160      |      40    \nneg |      33      |     167    \n\n\nAcuratetea pe setul de date de test, cu bigrame:  82.25 %. Matricea de confuzie:\n    |     pos      |     neg    \n--- + ------------ + ------------\npos |     156      |      44    \nneg |      27      |     173    \n"
     ]
    }
   ],
   "source": [
    "print(\"Acuratetea pe setul de date de test, cu cuvinte simple: \", acc_words * 100, \"%. Matricea de confuzie:\")\n",
    "print_confusion_matrix(cm_words)\n",
    "\n",
    "print(\"\\n\\nAcuratetea pe setul de date de test, cu bigrame: \", acc_bigrams * 100, \"%. Matricea de confuzie:\")\n",
    "print_confusion_matrix(cm_bigrams)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}